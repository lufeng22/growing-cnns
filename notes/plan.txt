Current sprint:
Plan and implement expandNode, expandEdge (include numConvAdded parameter)
Different growth speeds (expand all, expand youngest, expand oldest)

Functionality cards:
Join modes and weighting modes
Random initialization of new layers under certain weighting modes
Copy batch norm parameters from previous layer
Loss convergence (rename current lossConvergence to earlyStopping)
Growth step transfers weights with best validation performance

Errand cards:
Add ImageNet + other datasets
Add different block types
Dynamic batch sizes across growth steps using model size estimation (https://github.com/jacobkimmel/pytorch_modelsize)
Clean/break up main
Clean/break up testGrowthController.py
Add test names to ./runTests output
Parallelize across multiple GPUs
Fix argument structure for training/evaluation
Convert to package and fix imports
Add option for CPU only
